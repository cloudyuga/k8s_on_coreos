# Worker2

# Keys setup.

Lets Create the required directory and copy the previously generated keys in that directory. Keys and Certificates stored in the `/etc/kubernetes/ssl` are used by the kubelet service and other kubernetes cluster component.
```
$ sudo mkdir -p /etc/kubernetes/ssl
$ cd /home/core/
$ cp ca.pem kube-worker-2-worker.pem kube-worker-2-worker-key.pem /etc/kubernetes/ssl/
$ ls /etc/kubernetes/ssl
```
Set proper permission for private key.
```
$ sudo chmod 600 /etc/kubernetes/ssl/*-key.pem
$ sudo chown root:root /etc/kubernetes/ssl/*-key.pem
```
Create symlinks to the worker-specific key, which simplifies the use of keys later.
```
$ cd /etc/kubernetes/ssl/
$ sudo ln -s kube-worker-2-worker.pem worker.pem
$ sudo ln -s kube-worker-2-worker-key.pem worker-key.pem
```
# Network Setup.

Flannel provides a software defined overlay network for routing traffic to/from pods. Next up is to configure the flannel networking to allow Kubernetes to assign virtual IP addresses to pods.

Make a new directory for storing flannel options.
```
sudo mkdir -p /etc/flannel/

```
Then create an options file with the following command and save the content shown below. In following content do replacement as suggested below.
- Replace `174.138.76.103` in following command with the Public IP address of `Master Node`.
- Replace `174.138.76.107` in following command with the Public IP address of `Worker Node1`.
- Replace `174.138.76.108` in following command with the Public IP address of `Worker Node2`.

```
$ sudo vi /etc/flannel/options.env

FLANNELD_IFACE=174.138.76.108
FLANNELD_ETCD_ENDPOINTS=http://174.138.76.103:2379,http://174.138.76.107:2379,http://174.138.76.108:2379
```
Create a systemd drop-in, which is a method for appending or overriding parameters of a systemd unit. In this case we're appending two dependency rules. Create the following drop-in, which will use the above configuration when flannel starts.
```
$ mkdir /etc/systemd/system/flanneld.service.d/

$ sudo vi /etc/systemd/system/flanneld.service.d/40-ExecStartPre-symlink.conf

[Service]
ExecStartPre=/usr/bin/ln -sf /etc/flannel/options.env /run/flannel/options.env
```
# Docker Configuration

In order for flannel to manage the pod network in the cluster, Docker needs to be configured to use it. All we need to do is require that flanneld is running prior to Docker starting.

```
$ mkdir -p /etc/systemd/system/docker.service.d/
$ sudo vi /etc/systemd/system/docker.service.d/40-flannel.conf

[Unit]
Requires=flanneld.service
After=flanneld.service
[Service]
EnvironmentFile=/etc/kubernetes/cni/docker_opts_cni.env
```

Create the Docker CNI Options file.
```
$ mkdir -p /etc/kubernetes/cni/
$ sudo vi /etc/kubernetes/cni/docker_opts_cni.env

DOCKER_OPT_BIP=""
DOCKER_OPT_IPMASQ=""
```

We are using Flannel for networking so lets setup the Flannel CNI configuration as per shown below.
```
$ mkdir /etc/kubernetes/cni/net.d/
$ sudo vi /etc/kubernetes/cni/net.d/10-flannel.conf

{
    "name": "podnet",
    "type": "flannel",
    "delegate": {
        "isDefaultGateway": true
    }
}
```
# Create the kubelet service.
- Replace `174.138.76.103` in following command with the Public IP address of `Master Node`.
- Replace `174.138.76.108` in following command with the Public IP address of `Worker Node2`.

```
$ sudo vi /etc/systemd/system/kubelet.service

[Service]
Environment=KUBELET_IMAGE_TAG=v1.6.1_coreos.0
Environment="RKT_RUN_ARGS=--uuid-file-save=/var/run/kubelet-pod.uuid \
  --volume dns,kind=host,source=/etc/resolv.conf \
  --mount volume=dns,target=/etc/resolv.conf \
  --volume var-log,kind=host,source=/var/log \
  --mount volume=var-log,target=/var/log"
ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/manifests
ExecStartPre=/usr/bin/mkdir -p /var/log/containers
ExecStartPre=-/usr/bin/rkt rm --uuid-file=/var/run/kubelet-pod.uuid
ExecStart=/usr/lib/coreos/kubelet-wrapper \
  --api-servers=https://174.138.76.103 \
  --cni-conf-dir=/etc/kubernetes/cni/net.d \
  --network-plugin=${NETWORK_PLUGIN} \
  --container-runtime=docker \
  --register-node=true \
  --allow-privileged=true \
  --pod-manifest-path=/etc/kubernetes/manifests \
  --hostname-override=174.138.76.108 \
  --cluster_dns=10.3.0.10 \
  --cluster_domain=cluster.local \
  --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml \
  --tls-cert-file=/etc/kubernetes/ssl/worker.pem \
  --tls-private-key-file=/etc/kubernetes/ssl/worker-key.pem
ExecStop=-/usr/bin/rkt stop --uuid-file=/var/run/kubelet-pod.uuid
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

# Set Up the kubernetes services.

Make a new directory for Kubernetes manifests which define the rest of the services that run on the worker node2.

```
$ mkdir -p /etc/kubernetes/manifests/
```
### Set Up the kube-proxy pod.
Kubernetes directs traffic from outside the cluster to the pods using proxies which are needed on every node. Create one on the master node using the yaml file below.
- Replace `174.138.76.103` in following command with the Public IP address of `Master Node`.

```
$ sudo vi /etc/kubernetes/manifests/kube-proxy.yaml

apiVersion: v1
kind: Pod
metadata:
  name: kube-proxy
  namespace: kube-system
spec:
  hostNetwork: true
  containers:
  - name: kube-proxy
    image: quay.io/coreos/hyperkube:v1.6.1_coreos.0
    command:
    - /hyperkube
    - proxy
    - --master=174.138.76.103
    - --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml
    securityContext:
      privileged: true
    volumeMounts:
    - mountPath: /etc/ssl/certs
      name: "ssl-certs"
    - mountPath: /etc/kubernetes/worker-kubeconfig.yaml
      name: "kubeconfig"
      readOnly: true
    - mountPath: /etc/kubernetes/ssl
      name: "etc-kube-ssl"
      readOnly: true
  volumes:
  - name: "ssl-certs"
    hostPath:
      path: "/usr/share/ca-certificates"
  - name: "kubeconfig"
    hostPath:
      path: "/etc/kubernetes/worker-kubeconfig.yaml"
  - name: "etc-kube-ssl"
    hostPath:
      path: "/etc/kubernetes/ssl"
```

### Set Up kubeconfig.

In order to facilitate secure communication between Kubernetes components, kubeconfig can be used to define authentication settings. In this case, the kubelet and proxy are reading this configuration to communicate with the API.

```
$ sudo vi /etc/kubernetes/worker-kubeconfig.yaml

apiVersion: v1
kind: Config
clusters:
- name: local
  cluster:
    certificate-authority: /etc/kubernetes/ssl/ca.pem
users:
- name: kubelet
  user:
    client-certificate: /etc/kubernetes/ssl/worker.pem
    client-key: /etc/kubernetes/ssl/worker-key.pem
contexts:
- context:
    cluster: local
    user: kubelet
  name: kubelet-context
current-context: kubelet-context
```

# Load Changed Units
Go ahead and reload the systemcl daemon to apply the changes.
```
$ sudo systemctl daemon-reload
```
# Configure Flannel service IP Range.
Make sure your `etcd` docker container is running.  Lets set Flannel Range IP.
```
$ etcdctl set /coreos.com/network/config '{ "Network": "10.1.0.0/16" }'
```
# Start Flannel service.
Start the Flannel service. Check the status of Flannel service and ake sure that Flannel service will start after boot so enable the Flannel service.
```
$ sudo systemctl start flanneld
$ sudo systemctl status flanneld
$ sudo systemctl enable flanneld
```
# Start kubelet service.
With all of the configuration and manifest files in place, start the kubelet service and Check the staus of kubelet service. Make sure that kubelet service will start after boot so make enable the kubelet service.
```
$ sudo systemctl start kubelet
$ sudo systemctl status kubelet
$ sudo systemctl enable kubelet
```







